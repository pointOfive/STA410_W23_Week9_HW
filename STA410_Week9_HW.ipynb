{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e24d64",
   "metadata": {},
   "source": [
    "# STA410 Week 9 Programming Assignment (10 points)\n",
    "\n",
    "Welcome.\n",
    "\n",
    "## Rules\n",
    "\n",
    "\n",
    "0. **This is a paired or individual assignment.** Specific code solutions submitted for these assignments must be created either individually or in the context of a paired effort: ***group efforts of three or more are students are not allowed.*** Please seek homework partners in-person or on the course discussion board on piazza. **Paired students each separately submit their (common) work, including (agreeing) contribution of work statements for each problem.**\n",
    "  \n",
    "   > Students choosing to work individually must work in accordance with the [University Student Academic Integrity values](https://www.artsci.utoronto.ca/current/academic-advising-and-support/student-academic-integrity)  of \"honesty, trust, fairness, respect, responsibility and courage.\" Students working in pairs may share work without restriction within their pair, but must otherwise work in accordance with the [University Student Academic Integrity values](https://www.artsci.utoronto.ca/current/academic-advising-and-support/student-academic-integrity) noted above. ***Getting and sharing \"hints\" from other classmates is allowed; but, the eventual code creation work and submission must be your own individual or paired creation.***\n",
    "   \n",
    "   \n",
    "1. **Do not delete or replace cells**: this erases `cell ids` upon which automated code tests are based.\n",
    "\n",
    "    - ***If you accidentally delete a required cell*** try \"Edit > Undo Delete Cells\" in the notebook editor; otherwise, redownload the notebook (so it has the correct required `cells ids`) and repopulate it with your answers (assuming you don't overwrite them when you redownload the notebook).\n",
    "\n",
    "   - ***You may add cells for scratch work*** but if required answers are not submitted through the provided cells where the answers are requested your answers may not be marked.\n",
    "\n",
    "  > You may check if `cell ids` are present and working by running the following command in a cell \n",
    "  >\n",
    "  > `! grep '\"id\":' <path/to/notebook>.ipynb`\n",
    "  >\n",
    "  > and making sure the `cell ids` **do not change** when you save your notebook.\n",
    "  >\n",
    "  >> ***If you are working in any environment other than*** [UofT JupyterLab](https://jupyter.utoronto.ca/hub/user-redirect/git-pull?repo=https://github.com/pointOfive/sta410hw0&branch=master&urlpath=/lab/tree/sta410hw0), [UofT JupyterHub](https://jupyter.utoronto.ca/hub/user-redirect/git-pull?repo=https://github.com/pointOfive/sta410hw0&branch=master), or [Google Colab](https://colab.research.google.com/github/pointOfive/sta410hw0/blob/master/sta410hw0.ipynb), your system must meet the following versioning requirements \n",
    "   >>\n",
    "   >>   - [notebook format >=4.5](https://github.com/jupyterlab/jupyterlab/issues/9729) \n",
    "   >>   - jupyter [notebook](https://jupyter.org/install#jupyter-notebook) version [>=6.2](https://jupyter-notebook.readthedocs.io/en/stable/) for \"classic\" notebooks served by [jupyterhub](https://jupyterhub.readthedocs.io/en/stable/quickstart.html)\n",
    "   >>   - [jupyterlab](https://jupyter.org/install) version [>=3.0.13](https://github.com/jupyterlab/jupyterlab/releases/tag/v3.0.13) for \"jupyterlab\" notebooks  \n",
    "   >>    \n",
    "   >> otherwise `cell ids` will not be supported and you will not get any credit for your submitted homework.  \n",
    "      \n",
    "2. **No cells may have any runtime errors** because this causes subsequent automated code tests to fail and you will not get marks for tests which fail because of previous runtime errors. \n",
    "\n",
    "  - Run time errors include, e.g., unassigned variables, mismatched parentheses, and any code which does not work when the notebook cells are sequentially run, even if it was provided for you as part of the starter code. ***It is best to restart and re-run the cells in your notebook to ensure there are no runtime errors before submitting your work.***\n",
    "    \n",
    "  - The `try`-`except` block syntax catches runtime errors and transforms them into `exceptions` which will not cause subsequent automated code tests to fail.  \n",
    "\n",
    "\n",
    "3. **No jupyter shortcut commands** such as `! python script.py 10` or `%%timeit` may be included in the final submission as they will cause subsequent automated code tests to fail.\n",
    "\n",
    "  - ***Comment out ALL jupyter shortcut commands***, e.g., `# ! python script.py 10` or `# %%timeit` in submitted notebooks.\n",
    "\n",
    "\n",
    "4. **Python library imports are limited** to only libraries imported in the starter code and the [standard python modules](https://docs.python.org/3/py-modindex.html). Importing additional libraries will cause subsequent automated code tests to fail.\n",
    "\n",
    "  > Unless a problem instructs differently, you may use any functions available from the libraries imported in the starter code; otherwise, you are expected to create your own Python functionality based on the Python stdlib (standard libary, i.e., base Python and standard Python modules).\n",
    "\n",
    "\n",
    "5. You are welcome and encouraged to adapt code you find available online into your notebook; however, if you do so you must provide a link to the utilized resource. ***If failure to cite such references is identified and confirmed, your mark will be immediately reduced to 0.***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06837861",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Unless a problem instructs differently, you may use any functions available from the following library imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging, os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72c4f22",
   "metadata": {},
   "source": [
    "# Problem 0 (required)\n",
    "\n",
    "Are you working with a partner to complete this assignment?  \n",
    "- If not, assign  the value of `None` into the variable `Partner`.\n",
    "- If so, assign the name of the person you worked with into the variable `Partner`.\n",
    "    - Format the name as `\"<First Name> <Last Name>\"` as a `str` type, e.g., \"Scott Schwartz\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e608b77",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Required: only worth points when not completed, in which case, you'll lose points\n",
    "Partner = #None\n",
    "# This cell will produce a runtime error until you assign a value to this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb02ffe",
   "metadata": {},
   "source": [
    "What was your contribution in completing the code for this assignments problems? Assign one of the following into each of the `Problem_X` variables below.\n",
    "\n",
    "- `\"I worked alone\"`\n",
    "- `\"I contributed more than my partner\"`\n",
    "- `\"My partner and I contributed equally\"`\n",
    "- `\"I contributed less than my partner\"`\n",
    "- `\"I did not contribute\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beae8e9",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Required: only worth points when not completed, in which case, you'll lose points\n",
    "Problem_1 = #\"I worked alone\"\n",
    "Problem_2 = #\"I worked alone\"\n",
    "# This cell will produce a runtime error until you assign a value to this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ba05a",
   "metadata": {},
   "source": [
    "# Problem 1 (5 points)\n",
    "\n",
    "Complete the function `newtons_method(f, x0, K=10, eps=1e-7)` for use with the $d$-variate [Schwefel function](https://www.sfu.ca/~ssurjano/schwef.html)\n",
    "\n",
    "$$418.9829d - \\sum_{i=1}^d x_i\\sin\\left(\\sqrt{|x_i|}\\right)$$\n",
    "\n",
    "\n",
    "  *This problem draws upon the outstanding materials created by [Sonja Surjanovic and Derek Bingham](https://www.sfu.ca/~ssurjano/index.html) of the [Department of Statistics and Actuarial Science at Simon Fraser University](https://www.sfu.ca/stat-actsci.html); specifically, their [optimization resources](https://www.sfu.ca/~ssurjano/optimization.html) which includes an extensive collection of multimodal functions.*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1abffb5",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "d = 3\n",
    "@tf.function(input_signature=(tf.TensorSpec(shape=[d], dtype=tf.float32), ))\n",
    "def schwefel(x):\n",
    "    y = tf.math.reduce_sum(x*tf.math.sin(tf.math.sqrt(tf.math.abs(x))))\n",
    "    return 418.9829*x.shape[0] - y\n",
    "\n",
    "def newtons_method(f, x0, K=10, eps=1e-7):\n",
    "    \n",
    "    '''\n",
    "    Newton's Method with TensorFlow\n",
    "    \n",
    "    f   : @tf.function(input_signature=(tf.TensorSpec(shape=[d], dtype=tf.float32), ))\n",
    "    x0  : [x0_0, x0_1, ..., x0_(d-1)] list initialization \n",
    "    K   : (default 10) number of Newton Method steps\n",
    "    eps : (default 1e-7) stopping criterion `||x_k - x_(k-1)||_2<eps`\n",
    "    \n",
    "    returns x_K.numpy().tolist()+[f(x_k).numpy()]\n",
    "            where `_k` is the last update made on which a stopping criteria (based on K or eps) was met\n",
    "    '''\n",
    "\n",
    "    x_k = tf.Variable(x0)\n",
    "    \n",
    "    # <complete>\n",
    "    # Note: Don't actually invert the matrix: X(k+1) = X(k) - (∇²f(X(k)))^-1 @ ∇f(X(k))\n",
    "    # Solve for X(k+1) using tf.linalg.solve...\n",
    "    \n",
    "    return x_k.numpy(),f(x_k).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3cbe00",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "- Examples of how to use TensorFlow to compute higher order partial derivatives are given here: https://www.tensorflow.org/guide/advanced_autodiff\n",
    "- You may ignore warning messages regarding \"triggered tf.function retracing\":\n",
    "    - these indicate that the same function is being repeatedly placed into the automatic differention graph, which happens intentionally in ***Newton's method*** since partial derivatives are being recalculated at different locations for each ***Newton step*** inside `for k in range(K)`.\n",
    "    - and the warnings may be silenced with \n",
    "    \n",
    "    ```python\n",
    "    import logging, os\n",
    "    logging.disable(logging.WARNING)\n",
    "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "    ```\n",
    "\n",
    "- If the computation of the ***Hessian*** $H$ is not ***symmetric***, $(H + H^T)/2$ will be ***symmetric***. \n",
    "- If the computation of the ***Hessian*** $H$ has `NaN`s or `0` diagonal elements then \"monkey patch\" them on the basis of the following functions \n",
    "    - `tf.where(tf.math.is_nan(H) & (tf.eye(H.shape[0])==1), 1e-7, H)`\n",
    "    - where, e.g., `H = np.ones((2,2)); H[0,0] = np.NaN; H = tf.Variable(H)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db2cb8b",
   "metadata": {},
   "source": [
    "## Problem 1 Questions 0-1 (2 points)\n",
    "\n",
    "Local minima will be found with you function for various initializations and parameter settings.\n",
    "\n",
    "- You do not need to make any variable assignments: your function will be called based on the parameterization specified in the problem prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8919df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just do not leave in a state that will produce a runtime errors when notebook cells are run sequentially.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted.\n",
    "\n",
    "# None of this will not cause problems with `cell ids` assuming your versioning supports `cell ids`\n",
    "# (as UofT JupyterHub, UofT JupyterLab, an Google Colab will).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606672cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f80aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01731dfb",
   "metadata": {},
   "source": [
    "## Problem 1 Question 2 (2 points)\n",
    "\n",
    "2. What is the location of the minimum value of the $d=3$ ***Schwefel function*** subject to the constraint $x_1, x_2, x_3 \\in [-100,100]$ and what is that minimum value?\n",
    "\n",
    "***Hint***: use the following code to find a good initial value for your `newton_method` function.\n",
    "\n",
    "```python\n",
    "grid_n = 11\n",
    "grid = np.meshgrid(*[np.linspace(100,-100,grid_n) for i in range(3)])\n",
    "f = grid[0].copy()\n",
    "f_min = grid[0].copy()\n",
    "for i in range(grid_n):\n",
    "    for j in range(grid_n):\n",
    "        for k in range(grid_n):\n",
    "            f[i,j,k] = schwefel(tf.Variable([grid[0][i,j,k],grid[1][i,j,k],grid[2][i,j,k]], dtype=tf.float32))\n",
    "\n",
    "# some things to look at\n",
    "#min(f.ravel())\n",
    "#for i in range(grid_n):\n",
    "#    print(min(f[i].ravel()))\n",
    "# min(f.ravel()), min(f[i].ravel())\n",
    "# plt.imshow(f[i])\n",
    "# grid[0][f==min(f.ravel())],grid[1][f==min(f.ravel())],grid[2][f==min(f.ravel())]\n",
    "            \n",
    "# this code is more general for different d\n",
    "#grid = np.meshgrid(*[np.linspace(100,-100,grid_n) for i in range(d)])\n",
    "#f = grid[0].flatten()\n",
    "#for i,x0 in enumerate(zip(*[g.ravel() for g in grid])):\n",
    "#    f[i] = schwefel(tf.Variable(x0))\n",
    "#min(f)      \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2879ecb",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 2 points [format: tuble of four numbers; or, the call to the function below\n",
    "                                         # with a good `initial_value` choice]\n",
    "p1q2 = # (x1,x2,x3,y) # newtons_method(schwefel, <initial_value>)\n",
    "\n",
    "# This cell will produce a runtime error until you assign a value to this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6821ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just do not leave in a state that will produce a runtime errors when notebook cells are run sequentially.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted.\n",
    "\n",
    "# None of this will not cause problems with `cell ids` assuming your versioning supports `cell ids`\n",
    "# (as UofT JupyterHub, UofT JupyterLab, an Google Colab will).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7fe8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d2ad0",
   "metadata": {},
   "source": [
    "## Problem 1 Question 3-4 (1 point)\n",
    "\n",
    "3. (0.5 points) Why is the choice of the initial value important for finding a global optimum for a function like the `schwefel` function? \n",
    "    \n",
    "    1. To increase the speed of convergence of the `newton_method` function\n",
    "    2. Because the `schwefel` function is not convex\n",
    "    3. Because the `newton_method` function won't converge for all initial values \n",
    "    4. It is not important\n",
    "\n",
    "\n",
    "4. (0.5 points) What's wrong with running the `newton_method` function for every initial value in the `grid` for the previous problem? \n",
    "\n",
    "    1. It takes a very long time\n",
    "    2. The grid is not dense enough\n",
    "    3. Nothing is wrong with it -- it is recommended\n",
    "    4. It's cheating to find an optimum with a grid search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae042f52",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 0.5 points each [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" based on the choices above]\n",
    "p1q3 = #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p1q4 = #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "# Uncomment the above and keep each only either \"A\" or \"B\" or \"C\" or \"D\"\n",
    "\n",
    "# This cell will produce a runtime error until the `p1q3` and `p1q4` variables are assigned values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e2e48",
   "metadata": {},
   "source": [
    "# Problem 2 (5 points)\n",
    "\n",
    "This problem will examine ***Newton's root-finding method*** and related methods for univariate functions such as \n",
    "\n",
    "$$f(x) = \\frac{\\log x}{1+x}$$\n",
    "\n",
    "*This problem is inspired by Example 2.2 **A Simple Univariate Optimization, Continued** in Section 2.1.1 **Newton's Method** in Chapter 2 **Optimization and Solving Nonlinear Equations**, and Example 2.3 **A Simple Univeriate Optimization, Continued** in Section 2.1.4.1 **Scaling** in Chapter 2.1.4 **Fixed-Point Iteration** of the Givens and Hoeting **Computational Statistics** textbook (pages 26-30 and 32-34).*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4cbd92",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Problem 2 Questions 0-1 (1 point)\n",
    "\n",
    "Define the function `newton_raphson_iteration(f, df, x0, k, method='default')` which returns the iteration sequence created by ***Newton's root-finding method*** for any univariate function `f`.\n",
    "\n",
    "Add the option `method='aikens_accelerated'` to the `newton_raphson_iteration` function which applies [***Aitken's $\\Delta^2$ acceleration***](https://en.wikipedia.org/wiki/Aitken%27s_delta-squared_process) to ***Newton's method***.  That is, in order from $t=0, \\cdots, k-2$, each $x^{(t)}$ is replaced with \n",
    "\n",
    "$$x^{(t)} - \\frac{(x^{(t+1)} - x^{(t)})^2}{(x^{(t+2)} - x^{(t+1)}) - (x^{(t+1)} - x^{(t)})}$$\n",
    "    \n",
    "as in the example [here](https://en.wikipedia.org/wiki/Aitken%27s_delta-squared_process#Example_calculations), which can thus be completed in parallel since each sequetial adjustment does not depend on the previous adjustments.  When using ***Aitken's $\\Delta^2$ acceleration*** only the sequence from $t=0, \\cdots, k-2$ is returned since $x^{(k)}$ and $x^{(k-1)}$ are not adjusted under the formulation. \n",
    "\n",
    "  - ***Aitken's $\\Delta^2$ acceleration*** will speed up ***linear convergence*** to ***quadratic convergence***, but not necessarily improve ***order of convergence*** when it's already better than ***linearly convergent***. Thus, for ***Newton's method*** and the ***secant method*** which have order of convergence $2$ and $1.62$, respectively, it will not speedup convergence. However, it can nonetheless improve the precision of these methods, which there fore is the reason for its use with these methods. \n",
    "\n",
    "  - ***Aitken's $\\Delta^2$ acceleration*** is based on the fact that ***linear convergence*** has a predictable geometric series behavior. Thus, after seeing some iterations of the pattern, it's final conclusion can be predicted. The ***Aitken's $\\Delta^2$ acceleration*** formula is exactly the adjustment needed to make this prediction. \n",
    "\n",
    "\n",
    "For questions 0 and 1 use `f, x0 = lambda x: np.log(x)/(1+x), 0.1`.\n",
    "\n",
    "0. (0.5 points) What is the smallest input `k` for which `|f(x_k)|<1e-2` for `newton_raphson_iteration` with `method=\"default\"`?\n",
    "1. (0.5 points) What is the smallest input `k` for which `|f(x_k)|<1e-2` for  `newton_raphson_iteration`  with `method=\"aikens_accelerated\"`?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_raphson_iteration(f, df, x0, t, method = 'default'):\n",
    "    '''\n",
    "    The function implements the Newton-Raphson method for finding root x* so `f(x*)=0`\n",
    "    \n",
    "    f      : function on which to find root\n",
    "    x0     : intial value\n",
    "    k      : number of iterations resulting in sequence from \n",
    "             x_0 to x_k or x_0 to  x_(t-2) with acceleration\n",
    "    df     : derivative of f\n",
    "    method : either 'aikens_accelerated' or 'default' (no acceleration)\n",
    "\n",
    "    returns np.array((x_0,...,x_(t-2),x_(t-1), x_t)) or\n",
    "            np.array((x_0,...,x_(t-2))) when acceleration\n",
    "    '''   \n",
    "\n",
    "    xt = np.zeros(t+1)\n",
    "    xt[0] = x0\n",
    "    for i in range(1,t+1):\n",
    "        pass #<complete>\n",
    "            \n",
    "    if method == 'aikens_accelerated':\n",
    "        pass #<complete>\n",
    "        \n",
    "    return xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d80b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just do not leave in a state that will produce a runtime errors when notebook cells are run sequentially.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted.\n",
    "\n",
    "# None of this will not cause problems with `cell ids` assuming your versioning supports `cell ids`\n",
    "# (as UofT JupyterHub, UofT JupyterLab, an Google Colab will).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ed5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26547665",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point (0.5 each) [format: integer]\n",
    "p2q0 = # an integer, e.g., 10\n",
    "p2q1 = # an integer, e.g., 10\n",
    "\n",
    "# This cell will produce a runtime error until the `p2q0` and `p2q1` variables are assigned values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482a43d7",
   "metadata": {},
   "source": [
    "## Problem 2 Questions 2-3 (1 point)\n",
    "\n",
    "Define the function `the_secant_method(f, x0, k, method='default')` which returns the iteration sequence produced by the ***secant method for root-finding*** for any univariate function `f`.\n",
    "\n",
    "Add the option `method='aikens_accelerated'` to the `secant_method` function which applies [***Aitken's $\\Delta^2$ acceleration***](https://en.wikipedia.org/wiki/Aitken%27s_delta-squared_process) to the ***secant method***.  \n",
    "\n",
    "For questions 2 and 3 use `f, x0, x1 = lambda x: np.log(x)/(1+x), 0.05, 0.1`.\n",
    "\n",
    "2. (0.5 points) What is the smallest input `k` for which `|f(x_k)|<1e-2` for `the_secant_method` with `method=\"default\"`?\n",
    "3. (0.5 points) What is the smallest input `k` for which `|f(x_k)|<1e-2` for  `the_secant_method`  with `method=\"aikens_accelerated\"`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7233b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_secant_method(f, x0, x1, k, method = 'default'):\n",
    "    '''\n",
    "    The function implements the secant method for finding root x* so `f(x*)=0`\n",
    "    \n",
    "    f      : function on which to find root\n",
    "    x0     : first intial value\n",
    "    x1     : next intial value\n",
    "    k      : number of iterations resulting in sequence from \n",
    "             x_0 to x_k or x_0 to  x_(t-2) with acceleration\n",
    "    method : either 'aikens_accelerated' or 'default' (no acceleration)\n",
    "\n",
    "    returns np.array((x_0,...,x_(t-2),x_(t-1), x_t)) or\n",
    "            np.array((x_0,...,x_(t-2))) with acceleration\n",
    "    '''   \n",
    "\n",
    "    xt = np.zeros(t+1)\n",
    "    #<complete>\n",
    "    for i in range(1,t+1):\n",
    "        pass #<complete>\n",
    "            \n",
    "    if method == 'aikens_accelerated':\n",
    "        pass #<complete>\n",
    "        \n",
    "    return xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2916b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just do not leave in a state that will produce a runtime errors when notebook cells are run sequentially.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted.\n",
    "\n",
    "# None of this will not cause problems with `cell ids` assuming your versioning supports `cell ids`\n",
    "# (as UofT JupyterHub, UofT JupyterLab, an Google Colab will).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe8eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f95278",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point (0.5 each) [format: integer]\n",
    "p2q2 = # an integer, e.g., 10\n",
    "p2q3 = # an integer, e.g., 10\n",
    "\n",
    "# This cell will produce a runtime error until the `p2q2` and `p2q3` variables are assigned values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c17d78b",
   "metadata": {},
   "source": [
    "## Problem 2 Questions 4-5 (1 point)\n",
    "\n",
    "Define the function `fixed_point_iteration(f, x0, k, a, method='default')` which returns the iteration sequence produced by the ***fixed-point iteration algorithm for root-finding*** with ***scaling*** $\\alpha=$`a` for any univariate function `f`\n",
    "\n",
    "$$x^{(t)} = x^{(t-1)} + \\alpha f(x^{(t-1)}) \\quad \\Longrightarrow \\quad f(x^{(t-1)})=0 \\text{ if } x^{(t)}=x^{(t-1)} $$\n",
    "\n",
    "Add the option Add the option `method='steffensens_method'` to the `fixed_point_iteration` function which adds ***Aitken's $\\Delta^2$ acceleration*** to the ***fixed-point iteration algorithm*** (and is called ***Steffensen's method*** when applied to a ***fixed-point iteration algorithm***).\n",
    "\n",
    "- The ***order of convergence*** of a ***fixed-point iteration algorithm*** depends on $f$. Notice that ***Newton's method*** and its approximating ***secant method*** are also both ***fixed-point iteration algorithms*** since under those algorithms as well, if $x^{(t)}=x^{(t-1)}$ then $f(x^{(t-1)})=0$.\n",
    "\n",
    "- ***Fixed-point iteration algorithms*** converge in regions satisfying the ***lipschitz condition*** according to the ***contractive mapping theorem***. The $\\alpha$ scaling term is, interestingly, used to correct a failing ***lipschitz condition***.\n",
    "\n",
    "\n",
    "> For a satisfactory $\\alpha$ this is also called the ***method of parallel chords*** because, regardless of $t$, the slope of the line from point $(x_t, f(x_t))$ to point $(x_{t+1}, 0)$ is always constant since (\"rise over run\")\n",
    ">\n",
    "> $$\\frac{0-f(x_t)}{x_{t+1}-x_t} = -\\frac{1}{\\alpha}$$\n",
    ">\n",
    ">  which can be seen from the parallel slopes in, e.g., \n",
    ">  ```Python\n",
    "fx = lambda x: -4*x**3\n",
    "x, alpha = 2/3, 0.1\n",
    "for i in range(20):\n",
    "    x_t = x+alpha*fx(x)\n",
    "    plt.plot([x,x_t]+[x,x_t],[fx(x),0]+[fx(x),fx(x_t)],'k')\n",
    "    x = x_t\n",
    "> ```\n",
    "\n",
    "For questions 4 and 5 use `f, x0, a = lambda x: np.log(x)/(1+x), 0.1, -0.5`.\n",
    "\n",
    "4. (0.5 points) What is the smallest input `k` for which `|f(x_k)|<1e-2` for `fixed_point_iteration` with `method=\"default\"`?\n",
    "5. (0.5 points) What is the smallest input `k` for which `|f(x_k)|<1e-2` for  `fixed_point_iteration`  with `method=\"steffensens_method\"`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebbaa8",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def fixed_point_iteration(f, x0, k, a, method = 'default'):\n",
    "    '''\n",
    "    The function implements scaled Fixed-Point iteration finding root \n",
    "    `f(x*)=0` iff `x* = x* + af(x*)`\n",
    "    \n",
    "    f      : function on which to find root\n",
    "    x0     : intial value\n",
    "    k      : number of iterations resulting in sequence from \n",
    "             x_0 to x_k or x_0 to  x_(t-2) with acceleration\n",
    "    a      : scaling factor alpha\n",
    "    method : either 'steffensens_method' or 'default' (no acceleration)\n",
    "\n",
    "    returns np.array((x_0,...,x_(t-2),x_(t-1), x_t)) or\n",
    "            np.array((x_0,...,x_(t-2))) with acceleration\n",
    "    '''\n",
    "    \n",
    "    xt = np.zeros(t+1)\n",
    "    xt[0] = x0\n",
    "    for i in range(1,t+1):\n",
    "        pass #<complete>\n",
    "\n",
    "    if method == 'steffensens_method':\n",
    "        pass #<complete>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f701bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just do not leave in a state that will produce a runtime errors when notebook cells are run sequentially.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted.\n",
    "\n",
    "# None of this will not cause problems with `cell ids` assuming your versioning supports `cell ids`\n",
    "# (as UofT JupyterHub, UofT JupyterLab, an Google Colab will).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36550fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba601b5",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point (0.5 each) [format: integer]\n",
    "p2q4 = # an integer, e.g., 10\n",
    "p2q5 = # an integer, e.g., 10\n",
    "\n",
    "# This cell will produce a runtime error until the `p2q4` and `p2q5` variables are assigned values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cde0547",
   "metadata": {},
   "source": [
    "## Problem 2 Questions 6-9 (2 points)\n",
    "\n",
    "For the following questions, with respect to convergence, choose the best of the following.\n",
    "\n",
    "- (A) newton_raphson_iteration - aikens_accelerated\n",
    "- (B) the_secant_method - aikens_accelerated\n",
    "- (C) fixed_point_iteration - steffensens_method\"\n",
    "- (D) None of the above\n",
    "\n",
    "6. (0.5 points) Which method is preferable for `f, x0, x1, a = lambda x: np.log(x)/(1+x), 4.0, 3.9, -0.5`?\n",
    "7. (0.5 points) Which method is preferable for `f, x0, x1, a = lambda x: np.log(x)/(1+x), 3.0, 2.9, -0.5`?\n",
    "8. (0.5 points) Which method is preferable for `f, x0, x1, a = lambda x: np.log(x)/(1+x), 3.0, 2.9, 0.5`?\n",
    "9. (0.5 points) Which is the best choice for `f, x0, x1, a = lambda x: np.log(x)/(1+x), 0.001, 0.002, -0.5`?\n",
    "\n",
    "***Hints***: \n",
    "\n",
    "- If you've not already done so, it might be helpful to examine `f = lambda x: np.log(x)/(1+x)` with \n",
    "\n",
    "  ```Python\n",
    "x=np.linspace(0,n,n+1)\n",
    "plt.plot(x,f(x))\n",
    "```\n",
    "\n",
    "- It will likely be helpful to examine, e.g., `fixed_point_iteration(f, x0=0.1, k=20, a=0.5, method='default')` as well as the `aikens_accelerated` and `steffensens_method` methods. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2cb0f",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 0.25 points each [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" based on the choices above]\n",
    "p2q6 = #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p2q7 = #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p2q8 = #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p2q9 = #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "# Uncomment the above and keep each only either \"A\" or \"B\" or \"C\" or \"D\"\n",
    "\n",
    "# This cell will produce a runtime error until the `p2q6`-`p2q9` variables are assigned values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fdbab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just do not leave in a state that will produce a runtime errors when notebook cells are run sequentially.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted.\n",
    "\n",
    "# None of this will not cause problems with `cell ids` assuming your versioning supports `cell ids`\n",
    "# (as UofT JupyterHub, UofT JupyterLab, an Google Colab will).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b5b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
